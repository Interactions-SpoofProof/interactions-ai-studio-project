{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Interactions-SpoofProof/interactions-ai-studio-project/blob/main/ver2_neural_network_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps for preparing the feature vectors for the neural network:\n",
        "1. Make all vectors the same size by truncating/padding with 0's so that dimensions are (1, 300, 768)\n",
        "2. Use normalization/standardization (I used standardization) (this is where preprocessed_feature_vectors.pkl ended)\n",
        "3. Reduce the embedding dimensions (768 -> 256) using PCA (this is where reduced_feature_vecs.pkl.gz ended)\n",
        "4. Use squeeze function to remove the 1 from the dimensions\n",
        "5. Flatten the feature vectors into 1D arrays since neural networks only accept 2D arrays in the form (num_samples, num_features)\n",
        "\n",
        "Note: I used GPU to train model so only took a few mins"
      ],
      "metadata": {
        "id": "vH61UpMHYhc-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV47qDB_5NpM",
        "outputId": "a97c02ac-03c4-42dc-87f3-285a15279d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Team Interactions: SpoofProof - AudioClassification/test_dataset_compressed.pkl.gz'\n",
        "\n",
        "with gzip.open(file_path, 'rb') as f:\n",
        "    test_feature_vecs = pickle.load(f)"
      ],
      "metadata": {
        "id": "49wp8d3j5qZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_feature_vecs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DShikaAS538u",
        "outputId": "15ef44cf-4972-44a1-96da-1868b685f41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 177, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import pickle\n",
        "file_path = '/content/drive/MyDrive/Team Interactions: SpoofProof - AudioClassification/test_dataset_compressed.pkl.gz'\n",
        "\n",
        "with gzip.open(file_path, 'rb') as f:\n",
        "    test_dataset = pickle.load(f) # contains 4 cols: file, audio, label, number_array"
      ],
      "metadata": {
        "id": "EgS3t3pk56tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: padding with 0's (10 secs)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Pad all sequences to 300\n",
        "padded_vecs = []\n",
        "for i in range(len(test_feature_vecs)):\n",
        "  padded_feature_vecs = pad_sequences(test_feature_vecs[i], maxlen=300, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "  #print(\"Padded feature vectors shape:\", padded_feature_vecs.shape)\n",
        "  padded_vecs.append(padded_feature_vecs)"
      ],
      "metadata": {
        "id": "K_SADXvXm64W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_vecs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T79Gxc4KpY7i",
        "outputId": "045579dc-5c54-42a5-92a6-f6e7b8cce17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 2: standardization (10 secs)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standardized_vecs = []\n",
        "\n",
        "for i in range(len(padded_vecs)):\n",
        "\n",
        "# Assuming padded_vecs[i] is a 3D numpy array: (num_samples, num_frames, embedding_dim)\n",
        "  num_samples, num_frames, embedding_dim = padded_vecs[i].shape\n",
        "\n",
        "# Reshape the features to 2D for standardization\n",
        "  flattened_features = padded_vecs[i].reshape(num_samples * num_frames, embedding_dim)\n",
        "\n",
        "# Apply standardization\n",
        "  scaler = StandardScaler()\n",
        "  standardized_features = scaler.fit_transform(flattened_features)\n",
        "\n",
        "# Reshape back to 3D\n",
        "  standardized_features = standardized_features.reshape(num_samples, num_frames, embedding_dim)\n",
        "  standardized_vecs.append(standardized_features)\n"
      ],
      "metadata": {
        "id": "MKMa9WF3nGlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standardized_vecs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xgfbMBVpxEN",
        "outputId": "f44d0b4b-194d-4f3a-b4ac-218b08d0d984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 3: Reduce the embedding dimensions from (768 -> 256) using PCA (3 mins)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "reduced_feature_vecs = []\n",
        "\n",
        "for i in range(len(standardized_vecs)):\n",
        "  num_samples, num_frames, embedding_dim = standardized_vecs[i].shape\n",
        "\n",
        "# Reshape to 2D (combine samples and frames into one dimension for PCA)\n",
        "  flattened_features = standardized_vecs[i].reshape(num_samples * num_frames, embedding_dim)\n",
        "\n",
        "# Perform PCA to reduce to 256 dimensions instead of 768\n",
        "  pca = PCA(n_components=256)\n",
        "  reduced_features = pca.fit_transform(flattened_features)\n",
        "\n",
        "# Reshape back to 3D: (num_samples, num_frames, 256)\n",
        "  reduced_feature_vec = reduced_features.reshape(num_samples, num_frames, 256)\n",
        "  reduced_feature_vecs.append(reduced_feature_vec)"
      ],
      "metadata": {
        "id": "hryZvDHGnJP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_feature_vecs[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxo2Nb-aqQTW",
        "outputId": "c4ba0df1-4559-4724-f1df-028d6ac0663c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 4: Use squeeze function to remove the extra 1 from the dimensions (1 sec)\n",
        "import numpy as np\n",
        "\n",
        "feature_vecs = np.array(reduced_feature_vecs)\n",
        "feature_vecs_squeezed = feature_vecs.squeeze(axis=1)"
      ],
      "metadata": {
        "id": "Mn0N9mMq_IMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vecs_squeezed[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP-OIfO8_nB-",
        "outputId": "098380bc-2652-4305-ce24-c23231a0429e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# don't use this code for flattening vectors\n",
        "#flattened_feature_vecs = []\n",
        "\n",
        "#for i in range(len(feature_vecs_squeezed)):\n",
        "  #reduced_feature_vecs[i] = np.array(feature_vecs_squeezed[i])\n",
        "  #flattened_feature_vec = feature_vecs_squeezed.reshape(feature_vecs_squeezed[i].shape[0], -1)\n",
        "  #flattened_feature_vecs.append(flattened_feature_vec)"
      ],
      "metadata": {
        "id": "Tj3VcJ8O6eAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 5: flatten feature vectors to 1D arrays instead of 2D\n",
        "#flattened_feature_vecs = feature_vecs_squeezed.reshape(feature_vecs.shape[0], -1)\n",
        "flattened_feature_vecs = feature_vecs_squeezed.reshape(feature_vecs_squeezed.shape[0], -1)\n",
        "flattened_feature_vecs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQZ9L6DVBzsd",
        "outputId": "10bc0e16-7625-46cb-c6c3-7b362b752c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76800,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.DataFrame(flattened_feature_vecs)\n",
        "test_df['label'] = labels"
      ],
      "metadata": {
        "id": "b8uutj2uQfh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open('/content/drive/MyDrive/Team Interactions: SpoofProof - AudioClassification/test_final_preprocessed_vectors.pkl.gz', 'wb') as f:\n",
        "    pickle.dump(test_df, f)"
      ],
      "metadata": {
        "id": "XYetzBapQ52Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#dataframe with the flattened feature vectors\n",
        "test_df = pd.DataFrame(flattened_feature_vecs)\n",
        "\n",
        "# label added as a new column in test_df\n",
        "labels = test_dataset['label'].to_list()\n",
        "test_df['label'] = labels"
      ],
      "metadata": {
        "id": "hDoL1i8T95Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_col = test_df.pop('label')\n",
        "test_df.insert(0, 'label', label_col)  # setting label as leftmost column"
      ],
      "metadata": {
        "id": "jZUZtPs3CQo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = test_df.drop('label', axis=1)\n",
        "y = test_df['label']"
      ],
      "metadata": {
        "id": "-og91JJ0B_eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "fbjIDpknDVQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqub7nTKGgDY",
        "outputId": "160c6901-043c-4742-c00d-7bbf83b058eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-bdf2f1288c57>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Input\n",
        "# Simplified model with smaller hidden layers\n",
        "model = Sequential()\n",
        "\n",
        "# Use Input layer for the first layer to specify input shape\n",
        "model.add(Input(shape=(X.shape[1],)))  # Specify the input shape here\n",
        "\n",
        "model.add(Dense(32, activation='relu'))  # Reduce number of neurons\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "KATSQEDADhW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model to data (40 sec)\n",
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2, shuffle=True)  # Adjust epochs and batch_size as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBlVYUJDE1xZ",
        "outputId": "21de87aa-f436-44c2-e90c-9dc801611b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.3717 - loss: 3.0335 - val_accuracy: 0.8325 - val_loss: 0.3986\n",
            "Epoch 2/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6029 - loss: 2.1979 - val_accuracy: 0.9000 - val_loss: 0.2170\n",
            "Epoch 3/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6759 - loss: 1.9279 - val_accuracy: 0.9300 - val_loss: 0.1643\n",
            "Epoch 4/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7171 - loss: 1.6667 - val_accuracy: 0.9375 - val_loss: 0.1482\n",
            "Epoch 5/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7548 - loss: 1.0674 - val_accuracy: 0.9150 - val_loss: 0.1639\n",
            "Epoch 6/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8049 - loss: 0.9876 - val_accuracy: 0.9300 - val_loss: 0.1857\n",
            "Epoch 7/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.7931 - loss: 0.9287 - val_accuracy: 0.9425 - val_loss: 0.1722\n",
            "Epoch 8/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7953 - loss: 0.7579 - val_accuracy: 0.9125 - val_loss: 0.1864\n",
            "Epoch 9/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8226 - loss: 0.6769 - val_accuracy: 0.9425 - val_loss: 0.1483\n",
            "Epoch 10/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8229 - loss: 0.5407 - val_accuracy: 0.9550 - val_loss: 0.1357\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bf4ce389480>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating model\n",
        "score = model.evaluate(X, y, verbose=0)\n",
        "print(f'Test Loss: {score[0]}, Test Accuracy: {score[1]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvXSyPGDE3ps",
        "outputId": "d5162b6a-0683-4b41-8618-5bfefeda4e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.09159397333860397, Test Accuracy: 0.9635000228881836\n"
          ]
        }
      ]
    }
  ]
}